{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNvm/OXfjsWU5OBUKtDJhqp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"oQpkIIY2tXXH"},"outputs":[],"source":["def mapper(sentence):\n","  tokens = sentence.split()  # Split sentence into words\n","  for token in tokens:\n","    yield token, 1  # Emit word as key, 1 as count\n"]},{"cell_type":"code","source":["def mapper(sentence):\n","  tokens = sentence.split()\n","  for i in range(len(tokens) - 1):\n","    yield (tokens[i], tokens[i+1]), 1  # Emit bigram as key, 1 as count"],"metadata":{"id":"6JnKxQSmtpD9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def reducer(word_counts, word_count):\n","  word, count = word_count\n","  word_counts[word] = (word_counts.get(word, (0, 0))[0] + count, word_counts.get(word, (0, 0))[1] + len(word))\n","  return word_counts"],"metadata":{"id":"5g5CV3a5tsFs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"X1K03Gr-0gBs"},"execution_count":null,"outputs":[]}]}